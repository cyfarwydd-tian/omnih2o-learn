this md file is built by chatgpt, more details will be update later
# omnih2o: A Personal Learning Project

Our Lab (NYU-Control/Robotics Research Lab) is currently conducting research on Vision-Language-Action (VLA) technologies utilizing the Unitree G1 humanoid robot platform. 

This repository is a personal exploration and study of the [omnih2o](https://github.com/LeCAR-Lab/human2humanoid.git) project. 

We aim to generate a comprehensive dataset of robot motion trajectories using the Unitree G1 platform to enhance the training of our Vision-Language-Action (VLA) models. By collecting diverse and high-quality motion data, we seek to improve the models' ability to interpret visual and linguistic inputs and execute corresponding actions effectively.



## ðŸ“Œ Acknowledgments

- Original Project: [omnih2o](https://github.com/LeCAR-Lab/human2humanoid.git)
- Author: [Original Author's Name](https://github.com/LeCAR-Lab)

I extend my gratitude to the original creators for their work, which serves as a valuable learning resource.


